{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Entrenar un modelo de NER usando Transfer-learning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import nltk\n",
    "import tensorflow as tf\n",
    "# Deshabilitar la GPU, necesaro para macs con M1\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "# Cargar transformrers\n",
    "from transformers import BertTokenizer, TFBertForTokenClassification\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T19:24:27.895960Z",
     "start_time": "2023-05-27T19:24:22.139662Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Descargar el corpus de CONLL 2002"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package conll2002 to /Users/salva/nltk_data...\n",
      "[nltk_data]   Package conll2002 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('conll2002')\n",
    "from nltk.corpus import conll2002\n",
    "# Load the corpus\n",
    "corpus = conll2002.iob_sents()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T19:24:27.993540Z",
     "start_time": "2023-05-27T19:24:27.896881Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preparar la entrada al formato de Token Classification\n",
    "El dataset está en un formato no útil para nosotros (Listas de tokens y listas de etiquetas IOB).\n",
    "Preparemos la entrada."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def prepare_input(corpus):\n",
    "    sentences, labels = [], []\n",
    "    for tagged_sentence in corpus:\n",
    "        sentence, _, tag = zip(*tagged_sentence)\n",
    "        sentences.append(\" \".join(sentence))\n",
    "        labels.append(list(tag))\n",
    "    return sentences, labels\n",
    "\n",
    "sentences, labels = prepare_input(corpus)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(\n",
    "    sentences, labels, test_size=0.2, random_state=42\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T19:24:29.017577Z",
     "start_time": "2023-05-27T19:24:27.993999Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tokenizar la entrada usando el tokenizador de BERT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "model_name = \"bert-base-cased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "# Tokenize and convert sentences to input format\n",
    "train_encodings = tokenizer(train_sentences, truncation=True, padding=True)\n",
    "val_encodings = tokenizer(val_sentences, truncation=True, padding=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T19:24:36.920133Z",
     "start_time": "2023-05-27T19:24:29.018012Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Convertir las etiquetas IOB a índices:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def convert_labels_to_ids(labels, label_map):\n",
    "    label_ids = []\n",
    "    for sent_labels in labels:\n",
    "        label_ids.append([label_map[label] for label in sent_labels])\n",
    "    return label_ids\n",
    "# Define the label mapping. Sort it to have O before. And then B before I.\n",
    "labels_set = set(sum(labels, []))\n",
    "label_list = sorted(labels_set, key=lambda e: \"0\" if e == \"O\" else e[2]+e[0])\n",
    "label_map = {label: i for i, label in enumerate(label_list)}\n",
    "# Convert labels to label IDs\n",
    "train_label_ids = convert_labels_to_ids(train_labels, label_map)\n",
    "val_label_ids = convert_labels_to_ids(val_labels, label_map)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T19:25:49.798721Z",
     "start_time": "2023-05-27T19:24:36.921389Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Crear los datasets de entrenamiento y validación"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "train_label_ids = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    train_label_ids, padding=\"post\", truncating=\"post\", maxlen=tokenizer.model_max_length)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(train_encodings),\n",
    "    train_label_ids\n",
    "))\n",
    "val_label_ids = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    val_label_ids, padding=\"post\", truncating=\"post\", maxlen=tokenizer.model_max_length)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    dict(val_encodings),\n",
    "    val_label_ids\n",
    "))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T19:26:28.776080Z",
     "start_time": "2023-05-27T19:25:49.801111Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Definir y compilar el modelo:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForTokenClassification.\n",
      "\n",
      "Some layers of TFBertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! To disable this behaviour please pass a loss argument, or explicitly pass `loss=None` if you do not want your model to compute a loss.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "model = TFBertForTokenClassification.from_pretrained(model_name, num_labels=len(label_map))\n",
    "# Prepare optimizer\n",
    "from transformers import create_optimizer\n",
    "TOTAL_EPOCHS = 3\n",
    "optimizer, schedule = create_optimizer(init_lr=2e-5, num_warmup_steps=0, num_train_steps=TOTAL_EPOCHS)\n",
    "# Compile\n",
    "model.compile(optimizer=optimizer, metrics=[tf.keras.metrics.sparse_categorical_accuracy, ] )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-27T19:28:33.960271Z",
     "start_time": "2023-05-27T19:28:32.875932Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Entrenar el modelo:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "  11/1783 [..............................] - ETA: 11:06:49 - loss: 1.7318 - sparse_categorical_accuracy: 0.8495"
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset.shuffle(1000).batch(16),\n",
    "          validation_data=val_dataset.batch(16),\n",
    "          epochs=TOTAL_EPOCHS)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-05-27T19:28:35.757461Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
