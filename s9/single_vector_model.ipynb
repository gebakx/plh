{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Semantic Text Similarity\n",
    "Este modelo utiliza gensim para convertir pares de vectores + puntuaciones en vectores (word embeddings).\n",
    "Dado un dataset, infiere la puntuación de similitud entre ambas frases."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Requisitos\n",
    "from gensim.models import TfidfModel\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.corpora import Dictionary\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-23T14:55:07.143009Z",
     "start_time": "2025-05-23T14:55:05.828592Z"
    }
   },
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "# Tipado\n",
    "from typing import Tuple, List"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-23T14:55:08.481500Z",
     "start_time": "2025-05-23T14:55:08.479325Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "# Cargar stopwords en Catalan\n",
    "# STOPWORDS_CA = {\"a\", \"abans\", \"ací\", \"ah\", \"així\", \"això\", \"al\", \"aleshores\", \"algun\", \"alguna\", \"algunes\", \"alguns\", \"alhora\", \"allà\", \"allí\", \"allò\", \"als\", \"altra\", \"altre\", \"altres\", \"amb\", \"ambdues\", \"ambdós\", \"anar\", \"ans\", \"apa\", \"aquell\", \"aquella\", \"aquelles\", \"aquells\", \"aquest\", \"aquesta\", \"aquestes\", \"aquests\", \"aquí\", \"baix\", \"bastant\", \"bé\", \"cada\", \"cadascuna\", \"cadascunes\", \"cadascuns\", \"cadascú\", \"com\", \"consegueixo\", \"conseguim\", \"conseguir\", \"consigueix\", \"consigueixen\", \"consigueixes\", \"contra\", \"d'un\", \"d'una\", \"d'unes\", \"d'uns\", \"dalt\", \"de\", \"del\", \"dels\", \"des\", \"des de\", \"després\", \"dins\", \"dintre\", \"donat\", \"doncs\", \"durant\", \"e\", \"eh\", \"el\", \"elles\", \"ells\", \"els\", \"em\", \"en\", \"encara\", \"ens\", \"entre\", \"era\", \"erem\", \"eren\", \"eres\", \"es\", \"esta\", \"estan\", \"estat\", \"estava\", \"estaven\", \"estem\", \"esteu\", \"estic\", \"està\", \"estàvem\", \"estàveu\", \"et\", \"etc\", \"ets\", \"fa\", \"faig\", \"fan\", \"fas\", \"fem\", \"fer\", \"feu\", \"fi\", \"fins\", \"fora\", \"gairebé\", \"ha\", \"han\", \"has\", \"haver\", \"havia\", \"he\", \"hem\", \"heu\", \"hi\", \"ho\", \"i\", \"igual\", \"iguals\", \"inclòs\", \"ja\", \"jo\", \"l'hi\", \"la\", \"les\", \"li\", \"li'n\", \"llarg\", \"llavors\", \"m'he\", \"ma\", \"mal\", \"malgrat\", \"mateix\", \"mateixa\", \"mateixes\", \"mateixos\", \"me\", \"mentre\", \"meu\", \"meus\", \"meva\", \"meves\", \"mode\", \"molt\", \"molta\", \"moltes\", \"molts\", \"mon\", \"mons\", \"més\", \"n'he\", \"n'hi\", \"ne\", \"ni\", \"no\", \"nogensmenys\", \"només\", \"nosaltres\", \"nostra\", \"nostre\", \"nostres\", \"o\", \"oh\", \"oi\", \"on\", \"pas\", \"pel\", \"pels\", \"per\", \"per que\", \"perquè\", \"però\", \"poc\", \"poca\", \"pocs\", \"podem\", \"poden\", \"poder\", \"podeu\", \"poques\", \"potser\", \"primer\", \"propi\", \"puc\", \"qual\", \"quals\", \"quan\", \"quant\", \"que\", \"quelcom\", \"qui\", \"quin\", \"quina\", \"quines\", \"quins\", \"què\", \"s'ha\", \"s'han\", \"sa\", \"sabem\", \"saben\", \"saber\", \"sabeu\", \"sap\", \"saps\", \"semblant\", \"semblants\", \"sense\", \"ser\", \"ses\", \"seu\", \"seus\", \"seva\", \"seves\", \"si\", \"sobre\", \"sobretot\", \"soc\", \"solament\", \"sols\", \"som\", \"son\", \"sons\", \"sota\", \"sou\", \"sóc\", \"són\", \"t'ha\", \"t'han\", \"t'he\", \"ta\", \"tal\", \"també\", \"tampoc\", \"tan\", \"tant\", \"tanta\", \"tantes\", \"te\", \"tene\", \"tenim\", \"tenir\", \"teniu\", \"teu\", \"teus\", \"teva\", \"teves\", \"tinc\", \"ton\", \"tons\", \"tot\", \"tota\", \"totes\", \"tots\", \"un\", \"una\", \"unes\", \"uns\", \"us\", \"va\", \"vaig\", \"vam\", \"van\", \"vas\", \"veu\", \"vosaltres\", \"vostra\", \"vostre\", \"vostres\", \"érem\", \"éreu\", \"és\", \"éssent\", \"últim\", \"ús\"}\n",
    "STOPWORDS_CA = {\"a\", \"al\", \"el\", \"la\", \"els\", \"les\", \"de\", \"un\", \"una\", \"algun\", \"alguna\", }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-23T14:55:10.982179Z",
     "start_time": "2025-05-23T14:55:10.979566Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "# Definir función de pre-procesado\n",
    "def preprocess(sentence: str) -> List[str]:\n",
    "    preprocessed = simple_preprocess(sentence)\n",
    "    preprocessed = [token for token in preprocessed if token not in STOPWORDS_CA]\n",
    "    return preprocessed"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-23T14:55:39.846622Z",
     "start_time": "2025-05-23T14:55:39.839815Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "# Modelos pre-entrenados\n",
    "# WV_MODEL_PATH = \"/Users/salva/Downloads/cc.ca.300.bin.gz\"\n",
    "WV_MODEL_PATH = '/Users/salva/Downloads/cc.ca.300.vec.gz'\n",
    "import gensim\n",
    "wv_model =  gensim.models.KeyedVectors.load_word2vec_format(WV_MODEL_PATH, binary=False)\n",
    "wv_model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-23T14:58:04.254349Z",
     "start_time": "2025-05-23T14:55:40.303605Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x107c39b10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "# Ejemplo de 10 pares de oraciones con puntuación de similitud asociada\n",
    "input_pairs = [\n",
    "    ('M\\'agrada el futbol', 'Disfruto veient partits de futbol', 4),\n",
    "    ('El cel està despejat', 'Fa un dia bonic', 4.5),\n",
    "    ('M\\'encanta viatjar', 'Explorar nous llocs és una passió', 3.5),\n",
    "    ('Prefereixo l\\'estiu', 'No m\\'agrada el fred de l\\'hivern', 2.5),\n",
    "    ('Tinc gana', 'Què hi ha per sopar?', 2),\n",
    "    ('La música em relaxa', 'Escoltar música és una teràpia', 3),\n",
    "    ('El llibre és emocionant', 'No puc deixar de llegir-lo', 4),\n",
    "    ('M\\'agrada la pizza', 'És el meu menjar preferit', 4.5),\n",
    "    ('Estic cansat', 'Necessito fer una migdiada', 1.5),\n",
    "    ('Avui fa molta calor', 'És un dia sofocant', 3.5)\n",
    "    ]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-23T14:58:16.013377Z",
     "start_time": "2025-05-23T14:58:16.007686Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "# Text Similarity (STS) dataset (principal per la Pràctica 4)\n",
    "train = load_dataset(\"projecte-aina/sts-ca\", split=\"train\")\n",
    "test = load_dataset(\"projecte-aina/sts-ca\", split=\"test\")\n",
    "val = load_dataset(\"projecte-aina/sts-ca\", split=\"validation\")\n",
    "all_data = load_dataset(\"projecte-aina/sts-ca\", split=\"all\")\n",
    "all_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-23T14:58:24.542260Z",
     "start_time": "2025-05-23T14:58:16.595919Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'sentence_1', 'sentence_2', 'label'],\n",
       "    num_rows: 3073\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "# Preprocesamiento de las oraciones y creación del diccionario\n",
    "sentences_1_preproc = [simple_preprocess(d[\"sentence_1\"]) for d in all_data]\n",
    "sentences_2_preproc = [simple_preprocess(d[\"sentence_2\"]) for d in all_data]\n",
    "scores = [d[\"label\"] for d in all_data]\n",
    "sentence_pairs = list(zip(sentences_1_preproc, sentences_2_preproc, scores))\n",
    "# Versión aplanada para poder entrenar el modelo\n",
    "sentences_pairs_flattened = sentences_1_preproc + sentences_2_preproc\n",
    "diccionario = Dictionary(sentences_pairs_flattened)\n",
    "diccionario"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-23T14:58:25.881487Z",
     "start_time": "2025-05-23T14:58:25.584735Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.corpora.dictionary.Dictionary at 0x165fb9290>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "print(sentence_pairs[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-23T14:58:26.908268Z",
     "start_time": "2025-05-23T14:58:26.906394Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['atorga', 'per', 'primer', 'cop', 'les', 'mencions', 'encarna', 'sanahuja', 'la', 'inclusió', 'de', 'la', 'perspectiva', 'de', 'gènere', 'en', 'docència', 'universitària'], ['creen', 'la', 'menció', 'encarna', 'sanahuja', 'la', 'inclusió', 'de', 'la', 'perspectiva', 'de', 'gènere', 'en', 'docència', 'universitària'], 3.5)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "# Cálculo de los pesos TF-IDF para las oraciones pre-procesadas\n",
    "corpus = [diccionario.doc2bow(sent) for sent in sentences_pairs_flattened]\n",
    "modelo_tfidf = TfidfModel(corpus)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-23T14:58:28.003478Z",
     "start_time": "2025-05-23T14:58:27.934262Z"
    }
   },
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "def map_tf_idf(sentence_preproc: List[str], dictionary: Dictionary, tf_idf_model: TfidfModel) -> Tuple[List[np.ndarray], List[float]]:\n",
    "    bow = dictionary.doc2bow(sentence_preproc)\n",
    "    tf_idf = tf_idf_model[bow]\n",
    "    vectors, weights = [], []\n",
    "    for word_index, weight in tf_idf:\n",
    "        word = dictionary.get(word_index)\n",
    "        if word in wv_model:\n",
    "            vectors.append(wv_model[word])\n",
    "            weights.append(weight)\n",
    "    return vectors, weights\n",
    "\n",
    "def map_pairs(\n",
    "        sentence_pairs: List[Tuple[str, str, float]],\n",
    "        dictionary: Dictionary = None,\n",
    "        tf_idf_model: TfidfModel = None,\n",
    ") -> List[Tuple[Tuple[np.ndarray, np.ndarray], float]]:\n",
    "    \"\"\"\n",
    "    Mapea los tripletes de oraciones a listas de (x, y), (pares de vectores, score)\n",
    "    :param sentence_pairs:\n",
    "    :param dictionary:\n",
    "    :param tf_idf_model:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Mapeo de los pares de oraciones a pares de vectores\n",
    "    pares_vectores = []\n",
    "    for i, (sentence_1, sentence_2, similitud) in enumerate(sentence_pairs):\n",
    "        sentence_1_preproc = preprocess(sentence_1) if isinstance(sentence_1, str) else sentence_1\n",
    "        sentence_2_preproc = preprocess(sentence_2) if isinstance(sentence_2, str) else sentence_2\n",
    "        # Si usamos TF-IDF\n",
    "        if tf_idf_model is not None:\n",
    "            # Cálculo del promedio ponderado por TF-IDF de los word embeddings\n",
    "            vectors1, weights1 = map_tf_idf(sentence_1_preproc, dictionary=dictionary, tf_idf_model=tf_idf_model, )\n",
    "            vectors2, weights2 = map_tf_idf(sentence_2_preproc, dictionary=dictionary, tf_idf_model=tf_idf_model, )\n",
    "            vector1 = np.average(vectors1, weights=weights1, axis=0, )\n",
    "            vector2 = np.average(vectors2, weights=weights2, axis=0, )\n",
    "        else:\n",
    "            # Cálculo del promedio de los word embeddings\n",
    "            vectors1 = [wv_model[word] for word in sentence_1_preproc if word in wv_model]\n",
    "            vectors2 = [wv_model[word] for word in sentence_2_preproc if word in wv_model]\n",
    "            vector1 = np.mean(vectors1, axis=0)\n",
    "            vector2 = np.mean(vectors2, axis=0)\n",
    "        # Añadir a la lista\n",
    "        pares_vectores.append(((vector1, vector2), similitud))\n",
    "    return pares_vectores"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-23T14:59:25.966982Z",
     "start_time": "2025-05-23T14:59:25.958556Z"
    }
   },
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "# Imprimir los pares de vectores y la puntuación de similitud asociada\n",
    "mapped = map_pairs(sentence_pairs, tf_idf_model=modelo_tfidf, dictionary=diccionario, )\n",
    "mapped[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-23T14:59:27.525330Z",
     "start_time": "2025-05-23T14:59:26.747599Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([-7.22131877e-03, -4.88683421e-03,  2.71017708e-02,  2.32332627e-02,\n",
       "         -9.60097482e-03, -3.16095435e-03,  2.90225599e-02, -1.75413820e-02,\n",
       "          2.93095319e-02, -1.60574403e-02, -6.04936805e-03,  1.49908545e-02,\n",
       "          1.00934507e-02,  1.84449753e-02,  2.16156266e-02,  2.13238810e-02,\n",
       "          8.69774586e-03,  6.13958934e-02,  2.18719114e-02,  1.01426407e-02,\n",
       "          1.16837708e-02,  3.24588305e-03, -1.32856906e-02,  5.77104877e-02,\n",
       "          1.54627187e-02,  2.13443526e-02, -3.82471218e-02,  6.23983637e-03,\n",
       "          7.31161386e-04,  8.99225741e-03, -4.87626204e-03,  1.08773269e-02,\n",
       "          1.30313145e-02, -3.86450925e-03,  7.23370200e-03, -1.75266524e-02,\n",
       "         -9.09778208e-03,  4.43412138e-02, -4.31998409e-04,  6.25044253e-04,\n",
       "         -1.13920750e-02, -1.82465011e-02, -8.11444328e-03, -8.18518457e-03,\n",
       "         -3.54176235e-03, -1.60820262e-01,  7.74505797e-03,  9.80261699e-03,\n",
       "          8.53058034e-03, -1.23878019e-02,  1.24134202e-02, -2.39070017e-03,\n",
       "         -3.17817092e-02, -6.78023514e-03, -1.43296539e-02,  2.57246362e-02,\n",
       "          2.62315431e-02,  1.36448970e-02, -9.16338087e-03,  1.39765626e-02,\n",
       "          4.86506819e-02, -3.05702791e-02, -1.73943639e-02, -2.01844855e-02,\n",
       "          3.91634927e-02,  1.06170025e-03, -2.25761531e-02, -2.53614495e-02,\n",
       "          1.06654209e-02,  3.99356146e-02,  1.90717986e-02,  5.49600371e-03,\n",
       "          2.08872278e-02,  1.34323488e-02,  1.14136353e-02, -2.26947543e-02,\n",
       "         -2.89445889e-02,  3.63149983e-03, -3.17429208e-02, -1.86948783e-02,\n",
       "          7.58524843e-03, -2.51519190e-02,  1.59076956e-02, -1.57653595e-02,\n",
       "         -1.32853988e-02,  1.84268937e-02,  1.35733292e-02, -1.35745752e-02,\n",
       "         -2.62841402e-02, -1.71081547e-03, -6.57123376e-02,  1.80123245e-02,\n",
       "          2.18237573e-02,  4.92439771e-03, -4.24249468e-03,  1.44695216e-02,\n",
       "          1.61562532e-02, -5.86160831e-03,  1.07315954e-02,  2.03850600e-02,\n",
       "         -9.68246967e-03, -9.98037382e-03,  6.31454679e-07, -2.24527261e-02,\n",
       "          5.15347347e-03, -1.18663279e-02, -4.56879624e-03,  4.84564375e-02,\n",
       "          5.10890407e-03, -1.10297034e-03, -5.12788351e-03, -1.27865401e-02,\n",
       "          1.69212758e-02, -2.37873653e-04,  7.97397964e-03, -1.12930849e-02,\n",
       "         -4.02350222e-04, -1.98382137e-02,  2.10519730e-03, -1.94884122e-03,\n",
       "         -1.41923877e-02,  1.53408167e-02, -3.14154498e-02,  5.16255789e-03,\n",
       "          6.93068941e-03,  1.27301166e-02,  2.95631792e-03, -1.99976450e-02,\n",
       "         -1.29251593e-02,  2.83612074e-02, -1.00102755e-02, -3.59831313e-03,\n",
       "          9.12615437e-03,  3.19957247e-02, -2.39536587e-03, -1.88541424e-03,\n",
       "          1.71505670e-02,  6.10816907e-02, -2.02739033e-02,  3.70995447e-04,\n",
       "         -1.79623004e-02, -9.18574379e-04,  2.46088662e-02, -5.23656944e-03,\n",
       "         -3.28713545e-02, -1.66103211e-02, -2.97392304e-02,  1.05556641e-02,\n",
       "          1.15840674e-02,  5.76075530e-02,  5.02314960e-02,  2.17064867e-02,\n",
       "          8.58374305e-03, -6.60827014e-02, -4.82426792e-03, -1.56691531e-02,\n",
       "          2.12149921e-02, -2.74767225e-02, -1.23504192e-02,  1.28560904e-02,\n",
       "          2.30588782e-02, -1.09581482e-02,  6.07751199e-03,  1.72556543e-02,\n",
       "         -1.97553865e-03,  1.22152828e-02,  1.04813740e-02,  1.40103719e-02,\n",
       "          5.37980764e-03, -5.76685295e-02,  1.36694746e-02, -2.36321303e-02,\n",
       "         -8.50384182e-03,  3.60939922e-02, -2.06882135e-03,  1.76951758e-02,\n",
       "          1.57728072e-02,  2.88058438e-02, -8.86882738e-03,  6.88743752e-02,\n",
       "          6.25128593e-03,  3.75693638e-03,  3.87385404e-05, -1.95502007e-02,\n",
       "         -5.08330865e-03, -6.56666336e-03, -4.60735302e-03, -1.69378997e-02,\n",
       "          2.03075495e-02, -4.75446082e-02, -2.89494102e-02, -7.66059492e-03,\n",
       "         -2.24331713e-03,  8.62236897e-02, -2.80728569e-02, -4.31060661e-03,\n",
       "          1.31037543e-02,  6.93664039e-03,  8.79472834e-03,  5.53005787e-02,\n",
       "         -3.09062304e-03, -1.42629341e-02, -2.72252156e-02,  1.37947659e-02,\n",
       "         -3.86245701e-03, -1.68961022e-03,  1.90346599e-02, -1.98370433e-02,\n",
       "          2.21129468e-04,  8.48248098e-03,  1.53173742e-02, -4.47935110e-02,\n",
       "          5.90692373e-02,  4.12743244e-03,  2.69058790e-02, -7.84230922e-03,\n",
       "         -1.00485311e-02,  3.48163964e-03, -7.07877696e-03, -8.69120567e-03,\n",
       "         -1.09471734e-02, -5.26084500e-03, -8.29154383e-03,  1.45321145e-02,\n",
       "          1.17931868e-02,  1.51625271e-03,  5.06379921e-05,  3.64201031e-02,\n",
       "         -5.98440757e-03,  4.41127321e-03, -2.08663335e-02, -1.70784310e-02,\n",
       "         -2.18255851e-02,  6.00788341e-03,  5.07507834e-03, -1.38918141e-02,\n",
       "         -6.91033048e-03,  1.14552128e-02,  6.34593222e-02, -1.32782786e-02,\n",
       "         -1.52115628e-02,  4.98272376e-02,  1.72577717e-02, -1.29923328e-02,\n",
       "         -1.60627377e-02,  4.10427215e-02, -2.45433983e-03,  5.57846760e-03,\n",
       "         -2.11911409e-02, -2.09040772e-03,  4.27414873e-02,  2.59594736e-02,\n",
       "         -2.21033701e-02, -9.22074085e-03,  6.56417001e-03, -6.15493147e-03,\n",
       "         -6.36646366e-03, -2.16802575e-02,  2.19316476e-02, -1.32581929e-03,\n",
       "         -8.58274602e-03,  1.45549130e-03, -1.33940025e-02, -4.33783476e-03,\n",
       "          9.55339827e-03, -2.29094632e-02, -3.11402989e-03, -1.97023859e-02,\n",
       "          2.13536615e-03, -1.45499117e-02,  2.32157588e-02, -2.51983588e-02,\n",
       "         -2.26461076e-02,  9.16354896e-03,  2.66498964e-02, -1.95218307e-02,\n",
       "         -5.17713434e-02, -2.78031737e-02, -2.49143180e-02,  5.64633386e-03,\n",
       "         -1.70476468e-02,  1.34696997e-02, -5.37980768e-03, -2.86228522e-02,\n",
       "          1.15971552e-02,  1.62302861e-02, -1.50279653e-02, -3.47484244e-02,\n",
       "         -2.68725549e-02, -6.37603429e-03,  1.05356869e-04, -1.25608841e-02,\n",
       "         -4.91036526e-03, -5.21338575e-04,  4.98603459e-02, -1.67891928e-03,\n",
       "         -2.89849270e-03, -2.52519604e-02,  1.43659082e-02, -1.06123175e-02]),\n",
       "  array([-6.83419957e-03, -1.18342274e-02,  2.81851265e-02,  1.56639266e-02,\n",
       "         -8.56577435e-04, -8.51332926e-04,  1.97378555e-02, -1.29571395e-02,\n",
       "          4.93545554e-02, -2.41754346e-02, -6.15790577e-03,  2.05138671e-02,\n",
       "          1.93670358e-02,  2.11652259e-02,  2.54499821e-02,  1.63368237e-02,\n",
       "          4.16049481e-03,  3.83112881e-02,  2.22273047e-02,  4.62837957e-03,\n",
       "          8.80235256e-03, -2.01674838e-03, -1.16806213e-02,  4.86109168e-02,\n",
       "          1.98380204e-02, -1.89877654e-03, -4.72341870e-02, -4.54726101e-03,\n",
       "         -7.67185251e-03, -5.59219061e-05, -9.20897783e-03,  7.59127691e-03,\n",
       "          7.42895688e-04, -6.14518295e-03,  1.84238488e-02, -2.73708592e-02,\n",
       "          3.67920039e-03,  5.15129104e-02,  4.80286734e-03, -9.51228594e-03,\n",
       "         -1.11621336e-02, -9.42123322e-03, -4.36669167e-03, -1.52258050e-02,\n",
       "          9.90805424e-04, -1.54695765e-01,  1.73456723e-02,  4.71676183e-03,\n",
       "          4.02265375e-03, -2.22887292e-02, -4.60747433e-03,  3.95980001e-03,\n",
       "         -4.49414413e-02, -1.66012033e-02, -1.11012129e-02,  2.86654471e-02,\n",
       "          2.77660979e-02,  2.29358544e-02, -9.27368574e-03,  1.76946555e-02,\n",
       "          3.86702123e-02, -2.49444389e-02,  8.16866338e-04, -1.31154861e-02,\n",
       "          4.54887142e-02,  1.82431527e-03, -9.26950632e-03, -1.15554111e-02,\n",
       "          2.80840740e-02,  1.72604205e-02,  5.92232558e-03,  1.80038366e-02,\n",
       "          4.91635839e-02,  2.28532993e-02,  6.92838741e-03, -3.29340996e-02,\n",
       "         -2.60844809e-02, -3.53558118e-03, -2.37629223e-02, -1.33396815e-02,\n",
       "          3.39014677e-02, -2.58249188e-02,  1.58621179e-02, -1.38280199e-02,\n",
       "         -1.94001082e-02,  3.23780085e-02,  8.73536972e-03, -1.06491400e-02,\n",
       "         -2.06113311e-02, -1.00204539e-02, -5.92414899e-02,  2.21567742e-02,\n",
       "          1.96703621e-02,  4.83981773e-03,  4.64754394e-03,  1.72329994e-02,\n",
       "          3.77878697e-03, -7.31476285e-03,  2.15761497e-02,  2.36946578e-02,\n",
       "         -3.94739185e-04, -3.15822189e-03,  6.27627253e-03, -1.63456528e-02,\n",
       "         -2.86408123e-03, -1.34084593e-02, -2.05908982e-02,  3.79488378e-02,\n",
       "         -2.59135821e-03, -5.99367373e-03, -5.48361672e-03, -2.25192984e-02,\n",
       "          1.53839963e-02, -1.96333146e-03,  1.04385230e-02, -9.95364947e-03,\n",
       "         -9.15884628e-04, -5.44193423e-03, -2.63560402e-03, -1.20995468e-02,\n",
       "         -1.94892631e-02,  5.10339449e-03, -3.99716956e-02,  6.63766081e-03,\n",
       "          2.83341507e-02,  1.61479897e-02, -6.24960469e-03, -2.01853115e-02,\n",
       "         -2.30493463e-02,  2.41974686e-02, -1.18435264e-02,  3.91196668e-03,\n",
       "          1.57427261e-02,  3.39905907e-02,  1.78401215e-02, -5.43773888e-03,\n",
       "          1.96007225e-02,  8.70553736e-02, -2.09045670e-02,  5.44575620e-03,\n",
       "         -1.74754817e-02, -6.31366838e-03,  4.67595758e-03,  1.15769349e-03,\n",
       "         -2.48051513e-02, -1.49467794e-02,  8.50755240e-03,  3.35060067e-02,\n",
       "          3.74447485e-03,  4.09239615e-02,  3.32012232e-02,  3.43022553e-02,\n",
       "          1.95873175e-03, -4.23116064e-02, -1.78572984e-03, -2.38531207e-02,\n",
       "          2.10662950e-03, -2.19738587e-02, -1.20522812e-02, -3.03089888e-03,\n",
       "          2.11344370e-02, -8.71930295e-03,  7.29551984e-03,  1.66129700e-02,\n",
       "         -1.27604342e-02,  9.56745217e-03,  6.98299118e-03,  2.53704170e-02,\n",
       "         -4.42790063e-03, -3.90480910e-02,  8.54313270e-03, -2.50870639e-02,\n",
       "         -3.21222553e-05,  1.70423389e-02,  1.84731972e-02,  2.96567194e-03,\n",
       "          2.61907966e-02,  1.49996948e-02, -2.33189960e-02,  6.46570743e-02,\n",
       "          3.11559877e-03,  2.37721322e-02,  1.93601322e-02, -2.57546712e-02,\n",
       "         -1.83501803e-02, -1.41467092e-02, -3.99285842e-03, -1.79875420e-02,\n",
       "          1.90183532e-02, -2.44178147e-02, -1.57051930e-02, -2.09854681e-02,\n",
       "          1.37791918e-03,  7.44763341e-02, -1.74727091e-02,  3.67230073e-03,\n",
       "          1.56129086e-02,  6.37680905e-04,  1.01134477e-02,  2.87668182e-02,\n",
       "          2.03147982e-02, -1.17364094e-02, -1.45116558e-02,  6.01164431e-03,\n",
       "         -7.51482784e-03, -1.18620916e-02,  1.71493723e-02, -1.25271817e-02,\n",
       "         -1.03429024e-02, -4.95697306e-03,  3.03381939e-02, -3.41038112e-02,\n",
       "          4.47540520e-02,  1.99627772e-02,  1.54856961e-02, -1.28739820e-02,\n",
       "         -1.37375703e-02,  7.22146110e-03, -1.12781470e-02, -3.54985917e-03,\n",
       "         -1.46177715e-02,  1.68767010e-02, -1.02305389e-03,  4.97828967e-03,\n",
       "         -4.69090611e-03, -7.10695948e-03,  5.32717242e-03,  2.88679476e-02,\n",
       "         -2.48944984e-03, -3.63596450e-04, -1.58664227e-02, -2.27195900e-02,\n",
       "         -1.06893757e-02, -1.09062554e-03,  1.24194070e-02,  1.34343369e-02,\n",
       "          2.25927407e-03,  5.54371125e-03,  6.09565856e-02, -9.14932218e-03,\n",
       "         -1.07793950e-02,  4.92963797e-02,  1.36362660e-02, -1.14051405e-02,\n",
       "         -1.74310632e-02,  5.70965599e-02, -1.19615038e-02,  1.05203062e-02,\n",
       "         -4.02353531e-03,  5.68556388e-03,  5.59104681e-02,  1.28396213e-02,\n",
       "         -1.06977573e-02, -1.08159224e-02, -1.46696972e-02, -9.03286637e-03,\n",
       "         -3.02932333e-04, -5.26778925e-04,  2.86689934e-02,  2.36106037e-03,\n",
       "         -4.98861461e-03,  6.93722282e-03, -7.73450376e-03, -8.31161353e-03,\n",
       "          7.77818995e-03, -6.43278433e-03, -1.27221542e-02,  1.05815064e-02,\n",
       "          2.84699066e-03, -2.10621337e-02, -3.27117528e-03, -2.31504872e-02,\n",
       "         -4.80825505e-03, -1.02471190e-02,  6.89615496e-03, -2.43042988e-02,\n",
       "         -1.73822640e-02, -2.59426005e-02, -2.67280864e-02,  1.26821842e-02,\n",
       "          1.60994342e-03,  3.71996485e-03, -5.48653625e-03, -1.88920388e-02,\n",
       "          1.97826725e-02,  4.47507107e-03, -1.87621528e-02, -2.91604958e-02,\n",
       "         -1.39914642e-02, -1.30793378e-02, -9.50955897e-04, -3.02010468e-02,\n",
       "          4.11583971e-03, -7.42575856e-03,  3.74844929e-02, -1.16436960e-02,\n",
       "         -1.95666894e-02, -1.67785357e-02,  2.49638147e-02, -8.38376810e-03])),\n",
       " 3.5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "# Definir el Modelo\n",
    "import tensorflow as tf\n",
    "\n",
    "def build_and_compile_model(hidden_size: int = 128, embedding_size: int = 300, learning_rate: float = 0.001) -> tf.keras.Model:\n",
    "    # Capa de entrada para los pares de vectores\n",
    "    input_1 = tf.keras.Input(shape=(embedding_size,))\n",
    "    input_2 = tf.keras.Input(shape=(embedding_size,))\n",
    "\n",
    "    # Capa oculta\n",
    "    first_projection = tf.keras.layers.Dense(\n",
    "        embedding_size,\n",
    "        # activation='tanh',\n",
    "        kernel_initializer=tf.keras.initializers.Identity(),\n",
    "        bias_initializer=tf.keras.initializers.Zeros(),\n",
    "    )\n",
    "    projected_1 = first_projection(input_1)\n",
    "    projected_2 = first_projection(input_2)\n",
    "\n",
    "    # Compute the cosine distance\n",
    "    projected_1 = tf.linalg.l2_normalize(projected_1, axis=1, )\n",
    "    projected_2 = tf.linalg.l2_normalize(projected_2, axis=1, )\n",
    "    output = 2.5 * (1.0 + tf.reduce_sum(projected_1 * projected_2, axis=1, ))\n",
    "\n",
    "    # Definir el modelo con las capas de entrada y salida\n",
    "    model = tf.keras.Model(inputs=[input_1, input_2], outputs=output)\n",
    "\n",
    "    # Compilar el modelo\n",
    "    model.compile(loss='mean_absolute_error',\n",
    "                  optimizer=tf.keras.optimizers.Adam(learning_rate))\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-23T14:59:33.852866Z",
     "start_time": "2025-05-23T14:59:29.286142Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[31mAttributeError\u001B[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[31mAttributeError\u001B[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[31mAttributeError\u001B[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[31mAttributeError\u001B[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[31mAttributeError\u001B[39m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "# Definir constantes de entrenamiento\n",
    "batch_size: int = 64\n",
    "num_epochs: int = 64\n",
    "train_val_split: float = 0.8"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-23T14:59:35.496461Z",
     "start_time": "2025-05-23T14:59:35.493997Z"
    }
   },
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": [
    "# Obtener x_train e y_train\n",
    "train_slice: int = int(len(mapped) * train_val_split)\n",
    "\n",
    "def pair_list_to_x_y(pair_list: List[Tuple[Tuple[np.ndarray, np.ndarray], int]]) -> Tuple[Tuple[np.ndarray, np.ndarray], np.ndarray]:\n",
    "    \"\"\"\n",
    "    Otiene las matrices X_1 (N x d) , X_2 (N x d), e Y (n) a partir de listas de parejas de vectores de oraciones - Listas de (d, d, 1)\n",
    "    :param pair_list:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    _x, _y = zip(*pair_list)\n",
    "    _x_1, _x_2 = zip(*_x)\n",
    "    return (np.array(_x_1), np.array(_x_2)), np.array(_y, dtype=np.float32, ) / 5.0\n",
    "\n",
    "# Obtener las listas de train y test\n",
    "x_train, y_train = pair_list_to_x_y(mapped[:train_slice])\n",
    "x_val, y_val = pair_list_to_x_y(mapped[train_slice:])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-23T15:10:37.501410Z",
     "start_time": "2025-05-23T15:10:37.479617Z"
    }
   },
   "outputs": [],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "source": [
    "# Preparar los conjuntos de datos de entrenamiento y validación\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(x_train)).batch(batch_size)\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-23T15:10:38.223552Z",
     "start_time": "2025-05-23T15:10:38.209238Z"
    }
   },
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T21:27:48.489533Z",
     "start_time": "2025-05-23T21:27:48.441012Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def build_and_compile_model(embedding_size: int = 300, learning_rate: float = 0.001) -> tf.keras.Model:\n",
    "    # Input layer\n",
    "    input_1 = tf.keras.Input(shape=(embedding_size,), name=\"input_vector_1\")\n",
    "    input_2 = tf.keras.Input(shape=(embedding_size,), name=\"input_vector_2\")\n",
    "\n",
    "    # hidden layer\n",
    "    first_projection_layer = tf.keras.layers.Dense(\n",
    "        embedding_size,\n",
    "        activation='tanh',\n",
    "        kernel_initializer=tf.keras.initializers.Identity(),\n",
    "        bias_initializer=tf.keras.initializers.Zeros(),\n",
    "        name=\"projection_layer\"\n",
    "    )\n",
    "    dropout = tf.keras.layers.Dropout(0.3, name=\"projection_dropout\")\n",
    "    projected_1_dense = dropout(first_projection_layer(input_1))\n",
    "    projected_2_dense = dropout(first_projection_layer(input_2))\n",
    "\n",
    "    # Normalize the projected vectors using Lambda layers\n",
    "    normalized_1 = tf.keras.layers.Lambda(\n",
    "        lambda x: tf.linalg.l2_normalize(x, axis=1), name=\"normalize_1\"\n",
    "    )(projected_1_dense)\n",
    "    normalized_2 = tf.keras.layers.Lambda(\n",
    "        lambda x: tf.linalg.l2_normalize(x, axis=1), name=\"normalize_2\"\n",
    "    )(projected_2_dense)\n",
    "\n",
    "    # Compute the custom similarity score using a Lambda layer\n",
    "    similarity_sum = tf.keras.layers.Lambda(\n",
    "        lambda x: tf.reduce_sum(x[0] * x[1], axis=1, keepdims=True), name=\"similarity_sum\"\n",
    "    )([normalized_1, normalized_2])\n",
    "\n",
    "    output = tf.keras.layers.Lambda(\n",
    "        lambda x: 0.5 * (1.0 + x), name=\"output_scaling\"\n",
    "    )(similarity_sum)\n",
    "\n",
    "    # Definir el modelo con las capas de entrada y salida\n",
    "    model = tf.keras.Model(inputs=[input_1, input_2], outputs=output, name=\"similarity_model\")\n",
    "\n",
    "    # Compilar el modelo\n",
    "    model.compile(\n",
    "        loss='mean_squared_error',\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "    )\n",
    "\n",
    "    return model\n"
   ],
   "outputs": [],
   "execution_count": 102
  },
  {
   "cell_type": "code",
   "source": [
    "# Construir y compilar el modelo\n",
    "model = build_and_compile_model()\n",
    "# tf.keras.utils.plot_model(model, show_shapes=True, show_layer_activations=True, )\n",
    "print(model.summary())\n",
    "# Entrenar el modelo\n",
    "model.fit(train_dataset, epochs=num_epochs, validation_data=val_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-23T21:27:56.086011Z",
     "start_time": "2025-05-23T21:27:48.967096Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"similarity_model\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"similarity_model\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)       \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape     \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m   Param #\u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mConnected to     \u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_vector_1      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m300\u001B[0m)       │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_vector_2      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m300\u001B[0m)       │          \u001B[38;5;34m0\u001B[0m │ -                 │\n",
       "│ (\u001B[38;5;33mInputLayer\u001B[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ projection_layer    │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m300\u001B[0m)       │     \u001B[38;5;34m90,300\u001B[0m │ input_vector_1[\u001B[38;5;34m0\u001B[0m… │\n",
       "│ (\u001B[38;5;33mDense\u001B[0m)             │                   │            │ input_vector_2[\u001B[38;5;34m0\u001B[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ projection_dropout  │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m300\u001B[0m)       │          \u001B[38;5;34m0\u001B[0m │ projection_layer… │\n",
       "│ (\u001B[38;5;33mDropout\u001B[0m)           │                   │            │ projection_layer… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ normalize_1         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m300\u001B[0m)       │          \u001B[38;5;34m0\u001B[0m │ projection_dropo… │\n",
       "│ (\u001B[38;5;33mLambda\u001B[0m)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ normalize_2         │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m300\u001B[0m)       │          \u001B[38;5;34m0\u001B[0m │ projection_dropo… │\n",
       "│ (\u001B[38;5;33mLambda\u001B[0m)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ similarity_sum      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)         │          \u001B[38;5;34m0\u001B[0m │ normalize_1[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m… │\n",
       "│ (\u001B[38;5;33mLambda\u001B[0m)            │                   │            │ normalize_2[\u001B[38;5;34m0\u001B[0m][\u001B[38;5;34m0\u001B[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output_scaling      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)         │          \u001B[38;5;34m0\u001B[0m │ similarity_sum[\u001B[38;5;34m0\u001B[0m… │\n",
       "│ (\u001B[38;5;33mLambda\u001B[0m)            │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_vector_1      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ input_vector_2      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ projection_layer    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> │ input_vector_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │ input_vector_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ projection_dropout  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ projection_layer… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │ projection_layer… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ normalize_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ projection_dropo… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ normalize_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ projection_dropo… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ similarity_sum      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ normalize_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │                   │            │ normalize_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output_scaling      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ similarity_sum[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m90,300\u001B[0m (352.73 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> (352.73 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m90,300\u001B[0m (352.73 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">90,300</span> (352.73 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step - loss: 0.1008 - val_loss: 0.1401\n",
      "Epoch 2/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 4ms/step - loss: 0.0815 - val_loss: 0.1305\n",
      "Epoch 3/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0753 - val_loss: 0.1252\n",
      "Epoch 4/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0710 - val_loss: 0.1209\n",
      "Epoch 5/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.0672 - val_loss: 0.1186\n",
      "Epoch 6/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0644 - val_loss: 0.1167\n",
      "Epoch 7/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0625 - val_loss: 0.1151\n",
      "Epoch 8/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0595 - val_loss: 0.1138\n",
      "Epoch 9/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0577 - val_loss: 0.1125\n",
      "Epoch 10/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0557 - val_loss: 0.1120\n",
      "Epoch 11/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0542 - val_loss: 0.1113\n",
      "Epoch 12/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0523 - val_loss: 0.1109\n",
      "Epoch 13/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0522 - val_loss: 0.1103\n",
      "Epoch 14/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0506 - val_loss: 0.1090\n",
      "Epoch 15/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.0494 - val_loss: 0.1089\n",
      "Epoch 16/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.0481 - val_loss: 0.1082\n",
      "Epoch 17/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0471 - val_loss: 0.1080\n",
      "Epoch 18/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0464 - val_loss: 0.1076\n",
      "Epoch 19/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0449 - val_loss: 0.1075\n",
      "Epoch 20/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0445 - val_loss: 0.1070\n",
      "Epoch 21/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0440 - val_loss: 0.1067\n",
      "Epoch 22/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0427 - val_loss: 0.1065\n",
      "Epoch 23/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0429 - val_loss: 0.1065\n",
      "Epoch 24/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0417 - val_loss: 0.1059\n",
      "Epoch 25/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0410 - val_loss: 0.1062\n",
      "Epoch 26/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.0408 - val_loss: 0.1057\n",
      "Epoch 27/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0399 - val_loss: 0.1054\n",
      "Epoch 28/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0394 - val_loss: 0.1053\n",
      "Epoch 29/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0389 - val_loss: 0.1050\n",
      "Epoch 30/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0388 - val_loss: 0.1049\n",
      "Epoch 31/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0380 - val_loss: 0.1048\n",
      "Epoch 32/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0375 - val_loss: 0.1047\n",
      "Epoch 33/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0376 - val_loss: 0.1047\n",
      "Epoch 34/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0371 - val_loss: 0.1046\n",
      "Epoch 35/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0366 - val_loss: 0.1041\n",
      "Epoch 36/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - loss: 0.0362 - val_loss: 0.1045\n",
      "Epoch 37/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0358 - val_loss: 0.1042\n",
      "Epoch 38/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0354 - val_loss: 0.1041\n",
      "Epoch 39/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0352 - val_loss: 0.1035\n",
      "Epoch 40/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0346 - val_loss: 0.1036\n",
      "Epoch 41/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0345 - val_loss: 0.1036\n",
      "Epoch 42/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0338 - val_loss: 0.1033\n",
      "Epoch 43/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step - loss: 0.0337 - val_loss: 0.1036\n",
      "Epoch 44/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0339 - val_loss: 0.1032\n",
      "Epoch 45/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0334 - val_loss: 0.1031\n",
      "Epoch 46/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0334 - val_loss: 0.1029\n",
      "Epoch 47/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0323 - val_loss: 0.1031\n",
      "Epoch 48/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0328 - val_loss: 0.1028\n",
      "Epoch 49/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0325 - val_loss: 0.1029\n",
      "Epoch 50/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0319 - val_loss: 0.1028\n",
      "Epoch 51/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0320 - val_loss: 0.1024\n",
      "Epoch 52/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0323 - val_loss: 0.1023\n",
      "Epoch 53/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0311 - val_loss: 0.1023\n",
      "Epoch 54/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0311 - val_loss: 0.1020\n",
      "Epoch 55/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0308 - val_loss: 0.1024\n",
      "Epoch 56/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0309 - val_loss: 0.1018\n",
      "Epoch 57/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0310 - val_loss: 0.1022\n",
      "Epoch 58/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0305 - val_loss: 0.1018\n",
      "Epoch 59/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0305 - val_loss: 0.1019\n",
      "Epoch 60/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0298 - val_loss: 0.1017\n",
      "Epoch 61/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0299 - val_loss: 0.1016\n",
      "Epoch 62/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0296 - val_loss: 0.1016\n",
      "Epoch 63/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0296 - val_loss: 0.1019\n",
      "Epoch 64/64\n",
      "\u001B[1m39/39\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - loss: 0.0298 - val_loss: 0.1018\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x3aca47ed0>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 103
  },
  {
   "cell_type": "code",
   "source": [
    "# Podemos evaluar el modelo si sólo utilizamos COS similarity. (Depende completamente de los Word Embeddings)\n",
    "from scipy.stats import pearsonr\n",
    "from scipy import spatial\n",
    "val = mapped[train_slice:]\n",
    "y_pred_baseline = []\n",
    "for (v1, v2), dist in val:\n",
    "    d = 1.0 - spatial.distance.cosine(v1, v2)\n",
    "    y_pred_baseline.append(d)\n",
    "# Calcular la correlación de Pearson entre las predicciones y los datos de prueba\n",
    "correlation, _ = pearsonr(np.array(y_pred_baseline), y_val.flatten())\n",
    "# Imprimir el coeficiente de correlación de Pearson\n",
    "print(f\"Correlación de Pearson: {correlation}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-23T21:27:56.120397Z",
     "start_time": "2025-05-23T21:27:56.109750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlación de Pearson: 0.43930761675943547\n"
     ]
    }
   ],
   "execution_count": 104
  },
  {
   "cell_type": "code",
   "source": [
    "from scipy.stats import pearsonr\n",
    "# Obtener las predicciones del modelo para los datos de prueba. En este ejemplo vamos a utilizar el corpus de training.\n",
    "y_pred: tf.RaggedTensor = model.predict(x_val)\n",
    "# Calcular la correlación de Pearson entre las predicciones y los datos de prueba\n",
    "correlation, _ = pearsonr(y_pred.flatten(), y_val.flatten())\n",
    "# Imprimir el coeficiente de correlación de Pearson\n",
    "print(f\"Correlación de Pearson: {correlation}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-05-23T21:27:56.239203Z",
     "start_time": "2025-05-23T21:27:56.137048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m20/20\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step \n",
      "Correlación de Pearson: 0.5313218622093188\n"
     ]
    }
   ],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T21:27:56.369002Z",
     "start_time": "2025-05-23T21:27:56.250260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scipy.stats import pearsonr\n",
    "# Obtener las predicciones del modelo para los datos de prueba. En este ejemplo vamos a utilizar el corpus de training.\n",
    "y_pred: tf.RaggedTensor = model.predict(x_train)\n",
    "# Calcular la correlación de Pearson entre las predicciones y los datos de prueba\n",
    "correlation, _ = pearsonr(y_pred.flatten(), y_train.flatten())\n",
    "# Imprimir el coeficiente de correlación de Pearson\n",
    "print(f\"Correlación de Pearson: {correlation}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m77/77\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 619us/step\n",
      "Correlación de Pearson: 0.7707306954929074\n"
     ]
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
